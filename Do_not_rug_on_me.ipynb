{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Do not rug on me.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpR/kynqPi1YNYhV8d4ON9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ydchen17/RugPullDetection/blob/main/Do_not_rug_on_me.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep"
      ],
      "metadata": {
        "id": "esHn1secYkf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8q2SAk68DbS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c136695-5b49-4cfc-b6fd-995522245ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonschema==3.2.0\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting web3\n",
            "  Downloading web3-5.28.0-py3-none-any.whl (499 kB)\n",
            "\u001b[K     |████████████████████████████████| 499 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 47.8 MB/s \n",
            "\u001b[?25hCollecting six>=1.11.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting attrs>=17.4.0\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting pyrsistent>=0.14.0\n",
            "  Downloading pyrsistent-0.18.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 52.8 MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "  Downloading setuptools-61.2.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 54.0 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
            "Collecting eth-account<0.6.0,>=0.5.7\n",
            "  Downloading eth_account-0.5.7-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting eth-typing<3.0.0,>=2.0.0\n",
            "  Downloading eth_typing-2.3.0-py3-none-any.whl (6.2 kB)\n",
            "Collecting lru-dict<2.0.0,>=1.1.6\n",
            "  Downloading lru-dict-1.1.7.tar.gz (10 kB)\n",
            "Collecting requests<3.0.0,>=2.16.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting protobuf<4,>=3.10.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.0 MB/s \n",
            "\u001b[?25hCollecting eth-utils<2.0.0,>=1.9.5\n",
            "  Downloading eth_utils-1.10.0-py3-none-any.whl (24 kB)\n",
            "Collecting websockets<10,>=9.1\n",
            "  Downloading websockets-9.1-cp37-cp37m-manylinux2010_x86_64.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 13.7 MB/s \n",
            "\u001b[?25hCollecting typing-extensions<5,>=3.7.4.1\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Collecting hexbytes<1.0.0,>=0.1.0\n",
            "  Downloading hexbytes-0.2.2-py3-none-any.whl (6.1 kB)\n",
            "Collecting eth-hash[pycryptodome]<1.0.0,>=0.2.0\n",
            "  Downloading eth_hash-0.3.2-py3-none-any.whl (8.8 kB)\n",
            "Collecting eth-abi<3.0.0,>=2.0.0b6\n",
            "  Downloading eth_abi-2.1.1-py3-none-any.whl (27 kB)\n",
            "Collecting aiohttp<4,>=3.7.4.post0\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 43.5 MB/s \n",
            "\u001b[?25hCollecting ipfshttpclient==0.8.0a2\n",
            "  Downloading ipfshttpclient-0.8.0a2-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 333 kB/s \n",
            "\u001b[?25hCollecting multiaddr>=0.0.7\n",
            "  Downloading multiaddr-0.0.9-py2.py3-none-any.whl (16 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 37.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting charset-normalizer<3.0,>=2.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting parsimonious<0.9.0,>=0.8.0\n",
            "  Downloading parsimonious-0.8.1.tar.gz (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting rlp<3,>=1.0.0\n",
            "  Downloading rlp-2.0.1-py2.py3-none-any.whl (20 kB)\n",
            "Collecting eth-keys<0.4.0,>=0.3.4\n",
            "  Downloading eth_keys-0.3.4-py3-none-any.whl (21 kB)\n",
            "Collecting eth-rlp<2,>=0.1.2\n",
            "  Downloading eth_rlp-0.3.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting eth-keyfile<0.6.0,>=0.5.0\n",
            "  Downloading eth_keyfile-0.5.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting bitarray<1.3.0,>=1.2.1\n",
            "  Downloading bitarray-1.2.2.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting cytoolz<1.0.0,>=0.9.0\n",
            "  Downloading cytoolz-0.11.2.tar.gz (481 kB)\n",
            "\u001b[K     |████████████████████████████████| 481 kB 66.4 MB/s \n",
            "\u001b[?25hCollecting toolz>=0.8.0\n",
            "  Downloading toolz-0.11.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting eth-rlp<2,>=0.1.2\n",
            "  Downloading eth_rlp-0.2.1-py3-none-any.whl (5.0 kB)\n",
            "Collecting varint\n",
            "  Downloading varint-1.0.2.tar.gz (1.9 kB)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting netaddr\n",
            "  Downloading netaddr-0.8.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 67.2 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting zipp>=0.5\n",
            "  Downloading zipp-3.7.0-py3-none-any.whl (5.3 kB)\n",
            "Building wheels for collected packages: bitarray, cytoolz, lru-dict, parsimonious, varint\n",
            "  Building wheel for bitarray (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bitarray: filename=bitarray-1.2.2-cp37-cp37m-linux_x86_64.whl size=107028 sha256=e4b27e79e552be078d756356286b401998fcc1803a8a6757cd106d0ecca4704e\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/c8/a0/4fb7317b7072d4b6a4366454e5bf229ff5bb9ba1f7de8ef90d\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1230849 sha256=b7b2a0164a7a9f71cb385e80f0910aade49681ba7be6b89035f31d15dd6acab7\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n",
            "  Building wheel for lru-dict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lru-dict: filename=lru_dict-1.1.7-cp37-cp37m-linux_x86_64.whl size=28404 sha256=3a6b4403a8a8936d2e3f148ee42b2597c4b3f591ad6541bc900b7843f6c3d274\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/0b/4e/aa8fec9833090cd52bcd76f92f9d95e1ee7b915c12093663b4\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-py3-none-any.whl size=42723 sha256=3c35fc2ee830e385fd50da1b0b0a3c2a37362ea1e136bccc66a6bd7006f9208a\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/5d/ba/f27d8af07306b65ee44f9d3f9cadea1db749a421a6db8a99bf\n",
            "  Building wheel for varint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for varint: filename=varint-1.0.2-py3-none-any.whl size=1980 sha256=56b797ce48f451dfe5df17177d84abd32c9dcadde13e9d182511d8e6dcd5f915\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/21/07/09f1c6a7d9b59377aa6d98da6efdd670f7ca40aabd93d02704\n",
            "Successfully built bitarray cytoolz lru-dict parsimonious varint\n",
            "Installing collected packages: toolz, eth-typing, eth-hash, cytoolz, six, eth-utils, zipp, varint, urllib3, typing-extensions, rlp, pycryptodome, parsimonious, netaddr, multidict, idna, hexbytes, frozenlist, eth-keys, charset-normalizer, certifi, base58, yarl, setuptools, requests, pyrsistent, multiaddr, importlib-metadata, eth-rlp, eth-keyfile, eth-abi, bitarray, attrs, asynctest, async-timeout, aiosignal, websockets, protobuf, lru-dict, jsonschema, ipfshttpclient, eth-account, aiohttp, web3\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 0.11.2\n",
            "    Uninstalling toolz-0.11.2:\n",
            "      Successfully uninstalled toolz-0.11.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.7.0\n",
            "    Uninstalling zipp-3.7.0:\n",
            "      Successfully uninstalled zipp-3.7.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2021.10.8\n",
            "    Uninstalling certifi-2021.10.8:\n",
            "      Successfully uninstalled certifi-2021.10.8\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyrsistent\n",
            "    Found existing installation: pyrsistent 0.18.1\n",
            "    Uninstalling pyrsistent-0.18.1:\n",
            "      Successfully uninstalled pyrsistent-0.18.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "nbclient 0.5.13 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 attrs-21.4.0 base58-2.1.1 bitarray-1.2.2 certifi-2021.10.8 charset-normalizer-2.0.12 cytoolz-0.11.2 eth-abi-2.1.1 eth-account-0.5.7 eth-hash-0.3.2 eth-keyfile-0.5.1 eth-keys-0.3.4 eth-rlp-0.2.1 eth-typing-2.3.0 eth-utils-1.10.0 frozenlist-1.3.0 hexbytes-0.2.2 idna-3.3 importlib-metadata-4.11.3 ipfshttpclient-0.8.0a2 jsonschema-3.2.0 lru-dict-1.1.7 multiaddr-0.0.9 multidict-6.0.2 netaddr-0.8.0 parsimonious-0.8.1 protobuf-3.19.4 pycryptodome-3.14.1 pyrsistent-0.18.1 requests-2.27.1 rlp-2.0.1 setuptools-61.2.0 six-1.16.0 toolz-0.11.2 typing-extensions-4.1.1 urllib3-1.26.9 varint-1.0.2 web3-5.28.0 websockets-9.1 yarl-1.7.2 zipp-3.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pkg_resources",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --force-reinstall jsonschema==3.2.0 web3 pycryptodome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eth-tester"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci5xAstVZUjX",
        "outputId": "bf416f43-0b06-4dd0-e17c-92b50229ec9a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eth-tester\n",
            "  Downloading eth_tester-0.6.0b6-py3-none-any.whl (69 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 69 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting semantic-version<3.0.0,>=2.6.0\n",
            "  Downloading semantic_version-2.9.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: rlp<3,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from eth-tester) (2.0.1)\n",
            "Requirement already satisfied: eth-utils<2.0.0,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from eth-tester) (1.10.0)\n",
            "Requirement already satisfied: eth-account<0.6.0,>=0.5.6 in /usr/local/lib/python3.7/dist-packages (from eth-tester) (0.5.7)\n",
            "Requirement already satisfied: eth-keys<0.4.0,>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from eth-tester) (0.3.4)\n",
            "Requirement already satisfied: eth-abi<3.0.0,>=2.0.0b4 in /usr/local/lib/python3.7/dist-packages (from eth-tester) (2.1.1)\n",
            "Requirement already satisfied: parsimonious<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from eth-abi<3.0.0,>=2.0.0b4->eth-tester) (0.8.1)\n",
            "Requirement already satisfied: eth-typing<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from eth-abi<3.0.0,>=2.0.0b4->eth-tester) (2.3.0)\n",
            "Requirement already satisfied: hexbytes<1,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from eth-account<0.6.0,>=0.5.6->eth-tester) (0.2.2)\n",
            "Requirement already satisfied: eth-rlp<2,>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from eth-account<0.6.0,>=0.5.6->eth-tester) (0.2.1)\n",
            "Requirement already satisfied: bitarray<1.3.0,>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from eth-account<0.6.0,>=0.5.6->eth-tester) (1.2.2)\n",
            "Requirement already satisfied: eth-keyfile<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from eth-account<0.6.0,>=0.5.6->eth-tester) (0.5.1)\n",
            "Requirement already satisfied: cytoolz<1.0.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from eth-keyfile<0.6.0,>=0.5.0->eth-account<0.6.0,>=0.5.6->eth-tester) (0.11.2)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.4.7 in /usr/local/lib/python3.7/dist-packages (from eth-keyfile<0.6.0,>=0.5.0->eth-account<0.6.0,>=0.5.6->eth-tester) (3.14.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz<1.0.0,>=0.9.0->eth-keyfile<0.6.0,>=0.5.0->eth-account<0.6.0,>=0.5.6->eth-tester) (0.11.2)\n",
            "Requirement already satisfied: eth-hash<0.4.0,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from eth-utils<2.0.0,>=1.4.1->eth-tester) (0.3.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from parsimonious<0.9.0,>=0.8.0->eth-abi<3.0.0,>=2.0.0b4->eth-tester) (1.16.0)\n",
            "Installing collected packages: semantic-version, eth-tester\n",
            "Successfully installed eth-tester-0.6.0b6 semantic-version-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall typing_extensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiB5wTjxZa_7",
        "outputId": "0e6cfcfa-4a4d-4d23-d9b9-e58659746553"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing_extensions\n",
            "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed typing-extensions-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/T2Project/RugPullDetection.git"
      ],
      "metadata": {
        "id": "EF1UP_t986lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066f93b8-b33a-4950-b6b9-30447ae711a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RugPullDetection'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 146 (delta 31), reused 49 (delta 16), pack-reused 58\u001b[K\n",
            "Receiving objects: 100% (146/146), 18.95 MiB | 16.96 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shared"
      ],
      "metadata": {
        "id": "GyTp_50zqQrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import configparser\n",
        "import subprocess\n",
        "from web3 import Web3\n",
        "\n",
        "class shared:\n",
        "  def init():\n",
        "    global INFURA_URL\n",
        "    global USE_POOL_INFURA\n",
        "    global USE_WALLET_INFURA\n",
        "    global API_KEY\n",
        "    global UNISWAP_FACTORY\n",
        "    global SUSHISWAP_FACTORY\n",
        "    global UNILOCK_ADDRESS\n",
        "    global EXCHANGES\n",
        "    global ETH_ADDRESS\n",
        "    global DEAD_ADDRESS\n",
        "    global WETH\n",
        "    global TOKEN_TOLERANCE\n",
        "    global POOLS\n",
        "    global FAKE_POOL\n",
        "    global MULTICALL_CONTRACT\n",
        "    global TRANSACTION\n",
        "    \n",
        "    global ROOT_FOLDER\n",
        "    global WEEK\n",
        "    global ABI\n",
        "    global ABI_FACTORY\n",
        "    global BLOCKSTUDY\n",
        "    global ABI_POOL\n",
        "    \n",
        "    global web3\n",
        "    global multicall\n",
        "\n",
        "    ROOT_FOLDER        = subprocess.run([\"git\", \"rev-parse\", \"--show-toplevel\"], check=True, universal_newlines=True, stdout=subprocess.PIPE).stdout.strip()\n",
        "    config = configparser.ConfigParser()\n",
        "    config.read(ROOT_FOLDER + \"/config.ini\")\n",
        "\n",
        "    # # Get infura node url and logic booleans\n",
        "    INFURA_URL         = config.get(\"NODE\", \"INFURA_URL\")\n",
        "    USE_POOL_INFURA    = config.getboolean(\"NODE\", \"USE_POOL_INFURA\")\n",
        "    USE_WALLET_INFURA  = config.getboolean(\"NODE\", \"USE_WALLET_INFURA\")\n",
        "    \n",
        "    # Get etherscan keys\n",
        "    API_KEY            = config.get(\"APIS\", \"ETHERSCAN_API_KEY\")\n",
        "\n",
        "    # Get tokens addresses\n",
        "    ETH_ADDRESS        = config.get(\"ADDRESS\", \"ETH_ADDRESS\")\n",
        "    DEAD_ADDRESS       = config.get(\"ADDRESS\", \"DEAD_ADDRESS\")\n",
        "    WETH               = config.get(\"ADDRESS\", \"WETH_ADDRESS\")\n",
        "    MULTICALL_CONTRACT = config.get(\"ADDRESS\", \"MULTICALL_CONTRACT\")\n",
        "\n",
        "    # Get routers addresses\n",
        "    UNISWAP_ADDRESS    = config.get(\"ROUTERS\", \"UNISWAP_ADDRESS\")\n",
        "    UNILOCK_ADDRESS    = config.get(\"ADDRESS\", \"UNILOCK_ADDRESS\")\n",
        "    SUSHISWAP_ADDRESS  = config.get(\"ROUTERS\", \"SUSHISWAP_ADDRESS\")\n",
        "    FAKE_POOL          = config.get(\"POOLS\", \"FAKE_POOL\")\n",
        "\n",
        "    # Get pools factories\n",
        "    UNISWAP_FACTORY    = config.get(\"FACTORIES\", \"UNISWAP_FACTORY\")\n",
        "\n",
        "    #Get log hashes\n",
        "    TRANSACTION        = config.get(\"LOG_HASHES\",\"TRANSACTION\")\n",
        "\n",
        "    EXCHANGES          = {\n",
        "        \"uniswap\": UNISWAP_ADDRESS.lower(),\n",
        "        \"sushiswap\": SUSHISWAP_ADDRESS.lower()\n",
        "    }\n",
        "    \n",
        "    TOKEN_TOLERANCE    = float(config.get(\"THRESHOLDS\", \"TOKEN_TOLERANCE\"))\n",
        "    # Define other globals not saved in config.ini\n",
        "    WEEK               = 4*60*24*7\n",
        "    ABI                = open(ROOT_FOLDER + \"/ABIs/normal_token_abi.txt\").read()\n",
        "    ABI_FACTORY        = open(ROOT_FOLDER + \"/ABIs/factory_abi.txt\").read()\n",
        "    ABI_POOL           = open(ROOT_FOLDER + \"/ABIs/abi_pool.txt\").read()\n",
        "    # Define global objects\n",
        "    BLOCKSTUDY        =  13152303\n",
        "\n",
        "    web3 = Web3(Web3.HTTPProvider(INFURA_URL))\n",
        "    # multicall =  Multicall(web3.eth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "-n1HjybSqQSm",
        "outputId": "6930c18e-42e6-4074-a2fb-4231348a10d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_dep_map\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3015\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pkg_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3016\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3017\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPKG_INFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   2812\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: _DistInfoDistribution__dep_map",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_parsed_pkg_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3006\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minfo\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m     \"\"\"\n\u001b[0m\u001b[1;32m   3008\u001b[0m     \u001b[0mPKG_INFO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'METADATA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   2812\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: _pkg_info",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8b5ce5dd1c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mweb3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeb3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/web3/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkg_resources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"web3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__name__'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;31m# backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mregister_loader_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_factory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \"\"\"Register `provider_factory` to make providers for `loader_type`\n\u001b[0;32m--> 342\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mloader_type\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPEP\u001b[0m \u001b[0;36m302\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__loader__\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mprovider_factory\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequire\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrequirements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    778\u001b[0m                         \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstaller\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                         \u001b[0mreplace_conflicting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace_conflicting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m                     )\n\u001b[0m\u001b[1;32m    781\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m                         \u001b[0mrequirers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequired_by\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mrequires\u001b[0;34m(self, extras)\u001b[0m\n\u001b[1;32m   2732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_dep_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m         \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m'requires.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'depends.txt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreqs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_sections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_dep_map\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3016\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPKG_INFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3018\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pkg_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsestr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3019\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pkg_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_compute_dependencies\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dep_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3027\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dep_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_parsed_pkg_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3007\u001b[0m     \"\"\"\n\u001b[1;32m   3008\u001b[0m     \u001b[0mPKG_INFO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'METADATA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3009\u001b[0;31m     \u001b[0mEQEQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([\\(,])\\s*(\\d.*?)\\s*([,\\)])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0megg_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0megg_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0megg_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_isdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/lib/python3.7/dist-packages/protobuf-3.17.3.dist-info/METADATA'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility"
      ],
      "metadata": {
        "id": "8ZSUkPhnp6qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Crypto.Hash import keccak\n",
        "\n",
        "\n",
        "def obtain_hash_event(event: str) -> str:\n",
        "    k = keccak.new(digest_bits=256)\n",
        "    k.update(bytes(event, encoding='utf-8'))\n",
        "    return '0x'+k.hexdigest()\n",
        "\n",
        "\n",
        "def obtain_events_from_abi(abi: dict) -> list:\n",
        "    events = []\n",
        "    for function in abi:\n",
        "        if function['type'] == 'event':\n",
        "            event = function['name'] + '('\n",
        "            for cont, element in enumerate(function['inputs']):\n",
        "                if cont == 0:\n",
        "                    event += element['type']\n",
        "\n",
        "                else:\n",
        "                    event += ','+element['type']\n",
        "\n",
        "                cont += 1\n",
        "\n",
        "            event  += ')'\n",
        "            events.append(event)\n",
        "\n",
        "    return events"
      ],
      "metadata": {
        "id": "RiSkOMfBp5ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from web3.datastructures import AttributeDict\n",
        "from hexbytes import HexBytes\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "shared.init()\n",
        "\n",
        "\n",
        "def get_rpc_response(method, list_params=[]):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    method: str\n",
        "        Indicates node method.\n",
        "    list_params: List[Dict[str, Any]]\n",
        "        List of request parameters.\n",
        "    Returns\n",
        "    -------\n",
        "    args_event: AttributeDict\n",
        "        Change number basis.\n",
        "    Example\n",
        "    -------\n",
        "        If we want token transfers of 0xa150Db9b1Fa65b44799d4dD949D922c0a33Ee606\n",
        "        between blocks [11000000, 11025824] then:\n",
        "        method: 'eth_getLogs'\n",
        "        list_params: [[{'address': '0xa150Db9b1Fa65b44799d4dD949D922c0a33Ee606',\n",
        "                    'fromBlock': '0xa7d8c0', 'toBlock': '0xa83da0',\n",
        "                    'topics': ['0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef']}]]\n",
        "    \"\"\"\n",
        "    url = shared.INFURA_URL\n",
        "    list_params = list_params or []\n",
        "    data = [{\"jsonrpc\": \"2.0\", \"method\": method, \"params\": params, \"id\": 1} for params in list_params]\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def change_log_dict(log_dict):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    log_dict: AttributeDict\n",
        "        Decoded logs.\n",
        "    Returns\n",
        "    -------\n",
        "    args_event: AttributeDict\n",
        "        Change number basis.\n",
        "    \"\"\"\n",
        "    dictionary = log_dict.copy()\n",
        "    dictionary['blockHash'] = HexBytes(dictionary['blockHash'])\n",
        "    dictionary['blockNumber'] = int(dictionary['blockNumber'], 16)\n",
        "    dictionary['logIndex'] = int(dictionary['logIndex'], 16)\n",
        "    for i in range(len(dictionary['topics'])):\n",
        "        dictionary['topics'][i] = HexBytes(dictionary['topics'][i])\n",
        "    dictionary['transactionHash'] = HexBytes(dictionary['transactionHash'])\n",
        "    dictionary['transactionIndex'] = int(dictionary['transactionIndex'], 16)\n",
        "    return AttributeDict(dictionary)\n",
        "\n",
        "\n",
        "def clean_logs(contract, myevent, log):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    contract: web3.eth.contract\n",
        "        Contract that contains the event.\n",
        "    myevent: str\n",
        "        string with event name.\n",
        "    log: List[AttributeDict]\n",
        "        List containing raw node response.\n",
        "    Returns\n",
        "    -------\n",
        "    args_event: AttributeDict\n",
        "        Decoded logs.\n",
        "    \"\"\"\n",
        "    log_dict = AttributeDict({'logs': log})\n",
        "    eval_string = 'contract.events.{}().processReceipt({})'.format(myevent, log_dict)\n",
        "    args_event = eval(eval_string)[0]\n",
        "    return args_event\n",
        "\n",
        "\n",
        "def get_logs(contract, myevent, hash_create, from_block, to_block, number_batches):\n",
        "    \"\"\"\n",
        "    Get event logs using recursion.\n",
        "    Parameters\n",
        "    ----------\n",
        "    contract: web3.eth.contract\n",
        "        Contract that contains the event.\n",
        "    myevent: str\n",
        "        string with event name.\n",
        "    hash_create: str\n",
        "        hash of the event.\n",
        "    from_block: int\n",
        "        Starting block.\n",
        "    to_block: int\n",
        "        Ending block.\n",
        "    number_batches: int\n",
        "        infura returns just 10k logs each call, therefore we need to split time series into batches.\n",
        "    Returns\n",
        "    -------\n",
        "    events_clean: list\n",
        "        List with all clean logs.\n",
        "    \"\"\"\n",
        "\n",
        "    events_clean = []\n",
        "    block_list = [int(from_block + i * (to_block - from_block) / number_batches) for i in range(0, number_batches)] + [\n",
        "        to_block]\n",
        "\n",
        "    block_list[0] -= 1\n",
        "    list_params = [[{\"address\": contract.address,\n",
        "                     \"fromBlock\": hex(block_list[i - 1] + 1),\n",
        "                     \"toBlock\": hex(block_list[i]),\n",
        "                     \"topics\": [hash_create]}] for i in range(1, number_batches + 1)]\n",
        "\n",
        "    logs = get_rpc_response(\"eth_getLogs\", list_params)\n",
        "    for j, log in enumerate(logs):\n",
        "        if list(log.keys())[-1] == \"result\":\n",
        "            for event in log['result']:\n",
        "                log_dict = change_log_dict(event)\n",
        "                events_clean += [clean_logs(contract, myevent, [log_dict])]\n",
        "        else:\n",
        "            events_clean += get_logs(contract, myevent, hash_create, int(list_params[j][0][\"fromBlock\"], 16),\n",
        "                                     int(list_params[j][0][\"toBlock\"], 16), 15)\n",
        "    return events_clean"
      ],
      "metadata": {
        "id": "-pi5YNJnpx4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from web3 import Web3, HTTPProvider\n",
        "shared.init()\n",
        "from itertools import islice\n",
        "\n",
        "\n",
        "def connect_to_web3():\n",
        "    \"\"\"\n",
        "    Connect to Web3 server.\n",
        "    Parameters\n",
        "    ----------\n",
        "    Returns\n",
        "    -------\n",
        "    res: bool\n",
        "        True if connection was succeeded, otherwise False\n",
        "    web3: Web3 Object\n",
        "    \"\"\"\n",
        "    web3 = Web3(HTTPProvider('https://mainnet.infura.io/v3/d6243bb783b44485ad6636b6c3411377'))\n",
        "    res = web3.isConnected()\n",
        "    return res, web3\n",
        "\n",
        "\n",
        "def split_chunks(data, n_elements):\n",
        "    \"\"\"\n",
        "    Splitting the calls to aggregate them properly.\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: np.array\n",
        "        Containing calls\n",
        "    n_elements: int\n",
        "        Calls we want to aggregate\n",
        "    Returns\n",
        "    -------\n",
        "    chunks: list\n",
        "        Calls in chunks\n",
        "    \"\"\"\n",
        "\n",
        "    chunks = []\n",
        "    n = len(data)\n",
        "    \n",
        "    if n % n_elements != 0:\n",
        "        n_chunks = int(n/n_elements)+1\n",
        "\n",
        "    else:\n",
        "        n_chunks = int(n/n_elements)\n",
        "            \n",
        "    for  i in range(n_chunks-1):\n",
        "        chunk = data[i*n_elements:(i+1)*n_elements]\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    chunks.append(data[(n_chunks-1)*n_elements:]) \n",
        "    return chunks\n",
        "\n",
        "\n",
        "def chunks(data, SIZE=10000):\n",
        "    it = iter(data)\n",
        "    for i in range(0, len(data), SIZE):\n",
        "        yield {k:data[k] for k in islice(it, SIZE)}\n",
        "\n",
        "\n",
        "def get_pools(dex, factory): #v2 or sushi\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    dex : str\n",
        "        Choose the DEX you want to get the pools from\n",
        "    factory : web3.eth.contract\n",
        "        factory get_contracts of dex\n",
        "    Returns\n",
        "    -------\n",
        "    pool_dic: Dict[str, float]\n",
        "        pool dictionary with the attributes 'address','dex','token0','token1','reserves0','reserves1','creation'\n",
        "    \"\"\"\n",
        "\n",
        "    hash_create = '0x0d3648bd0f6ba80134a33ba9275ac585d9d315f0ad8355cddefde31afa28d0e9'\n",
        "    if dex == 'uniswap_v2':\n",
        "        from_block = 10008355\n",
        "        to_block = shared.BLOCKSTUDY\n",
        "        number_batches = 20\n",
        "        pools = get_logs(factory, 'PairCreated', hash_create, from_block, to_block, number_batches)\n",
        "    \n",
        "    if dex == 'sushiswap':\n",
        "        from_block = 10822038\n",
        "        to_block = shared.BLOCKSTUDY\n",
        "        number_batches = 20\n",
        "        pools = get_logs(factory, 'PairCreated', hash_create, from_block, to_block, number_batches)\n",
        "\n",
        "    pool_dic = {}\n",
        "    tokens = {}\n",
        "    for pool in pools:\n",
        "        pool_address = pool.args.pair\n",
        "        token0 = pool.args.token0\n",
        "        token1 = pool.args.token1\n",
        "        tokens.update({token0:None})\n",
        "        tokens.update({token1:None})\n",
        "        pool_dic.update({pool_address:{ 'address':pool_address,\n",
        "                                        'dex':dex,\n",
        "                                        'token0':token0,\n",
        "                                        'token1':token1,\n",
        "                                        'reserves0':None,\n",
        "                                        'reserves1':None,\n",
        "                                        'creation':pool.blockNumber}})   \n",
        "\n",
        "    return pool_dic, tokens\n",
        "\n",
        "\n",
        "def events_to_json(events):\n",
        "    json_events = []\n",
        "    for event in events:\n",
        "        event_dict = dict(event)\n",
        "        # event_dict.pop('transactionHash')\n",
        "        event_dict['transactionHash'] = event_dict['transactionHash'].hex()\n",
        "        event_dict.pop('blockHash')\n",
        "        event_dict['args'] = dict(event.args)\n",
        "        json_events.append(event_dict)\n",
        "       \n",
        "    return json_events"
      ],
      "metadata": {
        "id": "Z5wggwdOWrqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_tokens&pools.py\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "shared.init()\n",
        "def get_token_and_pools(out_path, dex='uniswap_v2'):\n",
        "    \"\"\"\n",
        "    Get tokens and pools from sushiswap or uniswap_v2.\n",
        "    Parameters\n",
        "    ----------\n",
        "    out_path : str\n",
        "        Path to output directory.\n",
        "    dex : str\n",
        "        sushiswap or uniswap_v2 are currently allowed.\n",
        "    \"\"\"\n",
        "\n",
        "    factory = shared.web3.eth.contract(shared.UNISWAP_FACTORY, abi=shared.ABI_FACTORY)\n",
        "    pool_dic, tokens = get_pools(dex, factory)\n",
        "    pd.DataFrame(tokens.keys(), columns=[\"token_address\"]).to_csv(f\"{out_path}/tokens.csv\", index=False)\n",
        "\n",
        "    with open(f\"{out_path}/pool_dict.json\", \"w\") as outfile:\n",
        "        json.dump(pool_dic, outfile)\n",
        "\n",
        "    inverted_pool_dict = dict()\n",
        "    for pool in pool_dic.keys():\n",
        "        try:\n",
        "            inverted_pool_dict[pool_dic[pool]['token0']].append(pool_dic[pool])\n",
        "        except:\n",
        "            inverted_pool_dict[pool_dic[pool]['token0']] = [pool_dic[pool]]\n",
        "        try:\n",
        "            inverted_pool_dict[pool_dic[pool]['token1']].append(pool_dic[pool])\n",
        "        except:\n",
        "            inverted_pool_dict[pool_dic[pool]['token1']] = [pool_dic[pool]]\n",
        "\n",
        "    with open(f\"{out_path}/pools_of_token.json\", \"w\") as outfile:\n",
        "        json.dump(inverted_pool_dict, outfile)\n",
        "\n",
        "    print('Tokens and Pools downloaded!')\n",
        "\n",
        "\n",
        "# get_token_and_pools(\"../data\", dex='uniswap_v2')"
      ],
      "metadata": {
        "id": "spXBjR_L86c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "shared.init()\n",
        "\n",
        "def get_pool_events(event_name, hashed_event, pool_address, out_path, start_block, end_block):\n",
        "    \"\"\"\n",
        "    Get pool logs for a given pool and period.\n",
        "    This function saves the events as a json in out_path.\n",
        "    Parameters\n",
        "    ----------\n",
        "    event_name: str\n",
        "        Pool event in string format (example: Mint)\n",
        "    hashed_event: str\n",
        "        The hashed event. Use obtain_hash_event() if necessary.\n",
        "    pool_address : str\n",
        "        Token address.\n",
        "    out_path : str\n",
        "        Path to output directory.\n",
        "    start_block: float\n",
        "        Starting block.\n",
        "    end_block: float\n",
        "        Ending block.\n",
        "    \"\"\"\n",
        "\n",
        "    pool = shared.web3.eth.contract(pool_address, abi=shared.ABI_POOL)\n",
        "    try:\n",
        "        events = get_logs(pool, event_name, hashed_event, start_block, end_block, number_batches=10)\n",
        "    except Exception as err:\n",
        "        print(f\"Exception occured: {err}\")\n",
        "        return\n",
        "\n",
        "    json_events = events_to_json(events)\n",
        "    with open(f'{out_path}/{pool_address}.json', 'w+') as f:\n",
        "        json.dump(json_events, f)\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "FNas8lEDo9rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "\n",
        "def _obtain_tx_creation(token_address):\n",
        "    \"\"\"\n",
        "    Gets token tx creation hash via web scrapping.\n",
        "    Parameters\n",
        "    ----------\n",
        "    token_address: str\n",
        "        string corresponding to token address\n",
        "    Returns\n",
        "    -------\n",
        "        tx_creation hash if success, \"Not found\" otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    tx_hash_creation = \"Not found\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/'\n",
        "                             '537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
        "\n",
        "    r = requests.get(f'https://etherscan.io/address/{token_address}', headers=headers)\n",
        "    soup = BeautifulSoup(r.content, 'html.parser')\n",
        "    soup2 = soup.find_all('div', 'col-md-8')\n",
        "    for element in soup2:\n",
        "        if \"Creator Txn Hash\" in str(element):\n",
        "            for element2 in str(element).split():\n",
        "                if 'href' and 'tx' in str(element2):\n",
        "                    tx_hash_creation = str(element2[10:]).replace('\"', '')\n",
        "    if tx_hash_creation != \"Not found\":\n",
        "        return tx_hash_creation\n",
        "    return \"Not found\""
      ],
      "metadata": {
        "id": "QDaZj-PEpJ-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shared.init()\n",
        "def get_decimal_token(token_address):\n",
        "    \"\"\"\n",
        "    Gets token decimal given a token address.\n",
        "    Parameters\n",
        "    ----------\n",
        "    token_address: str\n",
        "        String containing token address.\n",
        "    Returns\n",
        "    -------\n",
        "    decimal: int\n",
        "        Int corresponding to token decimal.\n",
        "    \"\"\"\n",
        "\n",
        "    contract = shared.web3.eth.contract(token_address, abi=shared.ABI)\n",
        "    decimals = contract.functions.decimals().call()\n",
        "\n",
        "    return decimals"
      ],
      "metadata": {
        "id": "Hm5XlzwZpMI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "shared.init()\n",
        "\n",
        "def get_source_code(token_address, out_path):\n",
        "    \"\"\"\n",
        "    Obtains token source code/abi and saves in json format.\n",
        "    Parameters\n",
        "    ----------\n",
        "    token_address: str\n",
        "        token address in checksum format.\n",
        "    out_path : str\n",
        "        Path to output directory.\n",
        "    \"\"\"\n",
        "\n",
        "    source_code_endpoint = \"https://api.etherscan.io/api?\" \\\n",
        "                           \"module=contract\" \\\n",
        "                           \"&action=getsourcecode\" \\\n",
        "                           f\"&address={token_address}\" \\\n",
        "                           f\"&apikey={shared.API_KEY}\"\n",
        "    source_code = json.loads(requests.get(source_code_endpoint).text)['result']\n",
        "\n",
        "    with open(f\"{out_path}/{token_address}.json\", \"w\") as outfile:\n",
        "        json.dump(source_code, outfile)\n",
        "    outfile.close()"
      ],
      "metadata": {
        "id": "AJW8kc99pX2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from web3 import Web3\n",
        "shared.init()\n",
        "def get_transfers(token_address, out_path, start_block, end_block, decimal=18):\n",
        "    \"\"\"\n",
        "    Get transfer logs for a given token and period.\n",
        "    This function saves transfers as a csv in out_path.\n",
        "    Parameters\n",
        "    ----------\n",
        "    token_address : str\n",
        "        Token address.\n",
        "    out_path : str\n",
        "        Path to output directory.\n",
        "    decimal: float\n",
        "        Token decimal (usually 18).\n",
        "    start_block: int\n",
        "        Starting block.\n",
        "    end_block: int\n",
        "        Ending block.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialise contract objects and get the transactions.\n",
        "    try:\n",
        "        contract = shared.web3.eth.contract(Web3.toChecksumAddress(token_address), abi=shared.ABI)\n",
        "        transfers = get_logs(contract, \"Transfer\", hash_log, start_block, end_block, number_batches=1)\n",
        "    except Exception as err:\n",
        "        print(f\"Exception occured: {err}\")\n",
        "        return\n",
        "\n",
        "    # Save txs in a Dataframe.\n",
        "    txs = [[transaction['transactionHash'].hex(), transaction[\"blockNumber\"], transaction[\"args\"]['from'],\n",
        "            transaction[\"args\"]['to'], transaction[\"args\"]['value'] / 10 ** decimal] for transaction in transfers]\n",
        "    transfers = pd.DataFrame(txs, columns=[\"transactionHash\", \"block_number\", \"from\", \"to\", \"value\"])\n",
        "    transfers.to_csv(out_path + \"/\" + token_address + \".csv\", index=False)\n",
        "    return\n",
        "\n",
        "\n",
        "hash_log = obtain_hash_event('Transfer(address,address,uint256)')\n",
        "get_transfers('0xa150Db9b1Fa65b44799d4dD949D922c0a33Ee606', './', 11000000, 11025824) # example"
      ],
      "metadata": {
        "id": "x5xVc9pcpgpp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}